# -*- coding: utf-8 -*-
"""GITA FINAL.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nlm-EqvgQYo9os2cvPOs8RFajU-rOpHa
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install torch

import torch
from transformers import pipeline

print(f"PyTorch version: {torch.__version__}")
model_name = "facebook/bart-large-mnli"
classifier = pipeline("zero-shot-classification",model=model_name)
print("Transformers loaded successfully!")

label_sets = {
    "emotions": [
        "joy", "anger", "sadness", "fear", "trust", "disgust",
        "anticipation", "surprise", "peace", "love", "hope",
        "grief", "devotion", "awe", "detachment", "compassion"
    ]
}

import pandas as pd
import os
import glob
from tqdm import tqdm

def combine_text(path,file_type):
  df = glob.glob(os.path.join(path+'/*.'+file_type))
  result = pd.concat(pd.read_csv(file) for file in df)
  result.reset_index(drop=True,inplace=True)
  return result

def sentiment(main_folder, sub_dir):
    csv_files = glob.glob(os.path.join(main_folder + "/" + sub_dir, '*.csv'))
    dfs = []

    for file in tqdm(csv_files):
        df = pd.read_csv(file)

        # We'll store predictions for each label set in new columns
        for label_set_name, labels in label_sets.items():
            print(f"\n--- Testing Label Set: {label_set_name} ---")
            all_preds = []
            all_scores = []

            for verse in df['verse']:
                result = classifier(verse, candidate_labels=labels, multi_label=True)
                threshold = 0.5

                # Get labels with score above threshold
                preds = [label for label, score in zip(result['labels'], result['scores']) if score > threshold]
                scores = [round(score, 2) for score in result['scores'] if score > threshold]

                all_preds.append(", ".join(preds))
                all_scores.append(", ".join(map(str, scores)))

            # Store results in new columns
            df[f'predicted_labels_{label_set_name}'] = all_preds
            df[f'predicted_scores_{label_set_name}'] = all_scores

        dfs.append(df)

    return dfs

Shri_Purohit_Swami_df = combine_text('/content/drive/MyDrive/Processed_Text_Files/Shri_Purohit_Swami','csv')

Shri_Purohit_Swami_df

Eknath_Easwaran_df = combine_text('/content/drive/MyDrive/Processed_Text_Files/eknath_easwaran','csv')

Eknath_Easwaran_df

df3 = sentiment('/content/drive/MyDrive/Processed Text Files','mahatma gandhi')

result_df=pd.concat(df1+df2+df3)

result_df

import pandas as pd

# Create empty lists to store the combined predictions and scores
all_predicted_labels = []
all_predicted_scores = []

# Iterate through the rows of the result_df
for index, row in result_df.iterrows():
    # Combine predictions from all label sets for each verse
    combined_labels = []
    combined_scores = []
    for label_set_name in label_sets:  # Assuming label_sets is defined as in the original code
        labels = row[f'predicted_labels_{label_set_name}'].split(', ')
        scores = row[f'predicted_scores_{label_set_name}'].split(', ')

        # Add each label with its corresponding score to combined lists
        for i in range(len(labels)):
            if labels[i]: # Add label if not empty string
              combined_labels.append(labels[i])
              combined_scores.append(scores[i])

    # Append the combined predictions and scores to their respective lists
    all_predicted_labels.append(", ".join(combined_labels))
    all_predicted_scores.append(", ".join(combined_scores))

# Add the new columns to the result_df
result_df['all_predicted_labels'] = all_predicted_labels
result_df['all_predicted_scores'] = all_predicted_scores

result_df

result_df.drop(['Unnamed: 0'],axis=1,inplace=True)

result_df.reset_index(drop=True,inplace=True)

result_df

result_df=result_df[['verse','all_predicted_labels','all_predicted_scores']]

result_df

result_df.drop_duplicates(inplace=True)

result_df['all_predicted_labels'].replace('','Neutral',inplace=True)
result_df['all_predicted_scores'].replace('',100,inplace=True)

result_df

result_df.reset_index(drop=True,inplace=True)

neutral_count = result_df[result_df['all_predicted_labels'] == 'Neutral'].shape[0]
print(f"Number of neutral values: {neutral_count}")

result_df

result_df.to_csv('/content/drive/MyDrive/result.csv', index=False)

result = pd.read_csv('/content/drive/MyDrive/result.csv')

result

# prompt: calculate the occurence of each label in the all sentiment

label_counts = {}
for index, row in result.iterrows():
    labels = row['all_predicted_labels'].split(', ')
    for label in labels:
        if label in label_counts:
            label_counts[label] += 1
        else:
            label_counts[label] = 1

print("Occurrences of each label in 'all_predicted_labels':")
for label, count in label_counts.items():
    print(f"{label}: {count}")

# prompt: create a data frame for 3 columns namely , my labels,paper's category,rationale

import pandas as pd
columns = ['my labels', 'paper\'s category', 'rationale']
df_new = pd.DataFrame(columns=columns)
df_new

df_final = pd.read_csv('/content/drive/MyDrive/all_results.csv')



from collections import Counter
from itertools import chain

# Drop NaNs before splitting
valid_labels = df_final['predicted_labels'].dropna().astype(str).str.split(', ')
all_labels = list(chain.from_iterable(valid_labels))

Counter(all_labels).most_common()